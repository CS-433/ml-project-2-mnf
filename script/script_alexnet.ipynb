{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16800edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08031954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def load_image(infilename):\n",
    "    data = mpimg.imread(infilename)\n",
    "    return data\n",
    "\n",
    "# Concatenate an image and its groundtruth\n",
    "def concatenate_images(img, gt_img):\n",
    "    nChannels = len(gt_img.shape)\n",
    "    w = gt_img.shape[0]\n",
    "    h = gt_img.shape[1]\n",
    "    if nChannels == 3:\n",
    "        cimg = np.concatenate((img, gt_img), axis=1)\n",
    "    else:\n",
    "        gt_img_3c = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "        gt_img8 = img_float_to_uint8(gt_img)\n",
    "        gt_img_3c[:, :, 0] = gt_img8\n",
    "        gt_img_3c[:, :, 1] = gt_img8\n",
    "        gt_img_3c[:, :, 2] = gt_img8\n",
    "        img8 = img_float_to_uint8(img)\n",
    "        cimg = np.concatenate((img8, gt_img_3c), axis=1)\n",
    "    return cimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd317a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/training/\"\n",
    "train_path = data_path + \"images/\"\n",
    "label_path = data_path + \"groundtruth/\"\n",
    "image_path_list = os.listdir(train_path)\n",
    "\n",
    "image_path=os.path.join(train_path, image_path_list[0])\n",
    "label_pt=os.path.join(label_path, image_path_list[0])\n",
    "\n",
    "image = Image.open(image_path)\n",
    "label = Image.open(label_pt)\n",
    "\n",
    "image_array = np.array(image)\n",
    "label_array = np.array(label)\n",
    "\n",
    "# fig, ax= plt.subplots(1,2)\n",
    "# ax[0].imshow(image_array)\n",
    "# ax[1].imshow(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2164458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RoadSegmentationDataset(Dataset):\n",
    "    def __init__(self, data_dir, image_folder = 'images', mask_folder = 'groundtruth', transform = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Root directory of the dataset.\n",
    "            image_folder (str): Name of the folder containing road images.\n",
    "            mask_folder (str): Name of the folder containing segmentation masks.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.image_folder = os.path.join(data_dir, image_folder)\n",
    "        self.mask_folder = os.path.join(data_dir, mask_folder)\n",
    "        self.transform = transform\n",
    "\n",
    "        assert os.path.exists(self.image_folder), f\"Image folder '{self.image_folder}' not found.\"\n",
    "        assert os.path.exists(self.mask_folder), f\"Mask folder '{self.mask_folder}' not found.\"\n",
    "\n",
    "        self.image_list = sorted(os.listdir(self.image_folder))\n",
    "        self.mask_list = sorted(os.listdir(self.mask_folder))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_name = self.image_list[idx]\n",
    "        mask_name = self.mask_list[idx]\n",
    "\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        mask_path = os.path.join(self.mask_folder, mask_name)\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(mask_path).convert(\"L\"))    \n",
    "\n",
    "        means = torch.tensor([np.mean(image.astype(np.float32)[:,:,i]) for i in range(3)])\n",
    "        std = torch.tensor([np.std(image.astype(np.float32)[:,:,i]) for i in range(3)])\n",
    "        normalize = transforms.Normalize(mean = means, std = std)\n",
    "        tens = torch.tensor(np.transpose(image_array.astype(np.float32), (2, 1, 0))).unsqueeze(0)\n",
    "        normalized_input = normalize(tens)\n",
    "        lab = np.expand_dims(mask/np.max(label_array), axis=0)\n",
    "        mask = torch.tensor(lab.astype(np.float32)).unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return (normalized_input,mask)\n",
    "        return img_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10c34a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Image Shape: torch.Size([1, 3, 400, 400])\n",
      "Sample Label Shape: torch.Size([1, 1, 400, 400])\n"
     ]
    }
   ],
   "source": [
    "dataset = RoadSegmentationDataset(data_dir=data_path, transform=None)\n",
    "\n",
    "# Test the dataset initialization\n",
    "sample_img, sample_label = dataset[0]\n",
    "print(f\"Sample Image Shape: {sample_img.shape}\")\n",
    "print(f\"Sample Label Shape: {sample_label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a343af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.module):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
